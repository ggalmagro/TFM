\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}
\usepackage{mathtools}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\modulolinenumbers[5]

\journal{Applied Soft Computing}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frontmatter}

\title{Elsevier \LaTeX\ template\tnoteref{mytitlenote}}
\tnotetext[mytitlenote]{Fully documented templates are available in the elsarticle package on \href{http://www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}{CTAN}.}

%% Group authors per affiliation:
\author{Elsevier\fnref{myfootnote}}
\address{Radarweg 29, Amsterdam}
\fntext[myfootnote]{Since 1880.}

%% or include affiliations in footnotes:
\author[mymainaddress,mysecondaryaddress]{Elsevier Inc}
\ead[url]{www.elsevier.com}

\author[mysecondaryaddress]{Global Customer Service\corref{mycorrespondingauthor}}
\cortext[mycorrespondingauthor]{Corresponding author}
\ead{support@elsevier.com}

\address[mymainaddress]{1600 John F Kennedy Boulevard, Philadelphia}
\address[mysecondaryaddress]{360 Park Avenue South, New York}

\begin{abstract}
This template helps you to create a properly formatted \LaTeX\ manuscript.
\end{abstract}

\begin{keyword}
\texttt{elsarticle.cls}\sep \LaTeX\sep Elsevier \sep template
\MSC[2010] 00-01\sep  99-00
\end{keyword}

\end{frontmatter}

\linenumbers

\section{Introduction}

\section{Constrained Clustering}

Clustering is the task of grouping instances of a dataset into subsets. The criterion used to assign an instance to a given cluster is the similarity with the rest of elements in that cluster and the dissimilarity with the rest of instances of the dataset. In this way, the clustering process obtains subsets of instances of the initial data set that present high intra-similarity and low inter-similarity.

In most clustering applications it is common to have some kind of information about the data set to be analyzed. In constrained clustering this information is given in the form of pairs of instances. A constraint states whether the instances which it refers to must, or must not, be assigned to the same cluster. Using this type of information it is possible to obtain a better result than by using completely unsupervised clustering algorithms. 

Before formalizing the definition of constraints we must give a notation for the data set. We will note our dataset as $X$, which is a set of $N$ instances with $D$ features. We well refer to the instances of $X$ as $x$. Now, given the definition of dataset, we can define two types of constraints:

\begin{itemize}
	
	\item Must-link constraints $c_=(x_j,x_i)$: instances $x_i$ and $x_j$ from $X$ must be placed in the same cluster.
	
	\item Cannot-link constraints $c_{\neq}(x_i,x_j)$: instances $x_i$ and $x_j$ from $X$ cannot be assigned to the same cluster.
	
\end{itemize}

The goal of constrained clustering is to find a partition (or clustering) of $K$ clusters $C = {c_1 \cdots c_K}$ of the dataset $X$ that ideally satisfies all constraints in the constraints set. As in the original clustering problem, it must be fulfilled that the sum of instances in each cluster $c_i$ is equal to the number of instances in $X$, which we have defined as $N = |X| = \sum_{i = 1}^{K} |c_i| $.

Knowing how a constraint is defined, Must-link constraints---from now on ML---are an example of an equivalence relation; therefore, CL constraints are reflexive, transitive and symmetric. This way, given the constraints $c_=(x_a,x_b)$ and $c_=(x_b,x_c)$ then $c_=(x_a,x_c)$ is verified. In addition, if $x_a \in c_i$ and $x_b \in c_j$ are related by $c_=(x_a,x_b)$, then $c_=(x_c,x_d)$ is verified for any $x_c \in c_i$ and $x_d \in c_j$ \cite{xu2013improving}\cite{davidson2007survey}.

On the other hand, Cannot-link restrictions---from now on CL---do not constitute an equivalence relation, but they can be entailed. To illustrate that, we consider the instances $x_a \in c_i$ and $x_b \in c_j$, and the constraint $c_{\neq}(x_a,x_b)$, then is also true that $c_{\neq}(x_c,x_d)$ for all $x_c \in c_i$ and $x_d \in c_j$ \cite{davidson2007survey}. 

\textcolor{red}{Comentar la complejidad del problema?}

\section{Background}

\section{Brief Review of BRKGA Algorithm}

The biased random-key genetic algorithm---from now on BRKGA---was first proposed by Gon√ßalves and Resende \cite{gonccalves2011biased} as a generalization of the random-key genetic algorithm \cite{bean1994genetic}.

In BRKGA each solution---also called chromosome---is represented as a vector of values in the interval $[0,1]$. However, this vector is not a solution to the problem, it is only a representation of it. This allows us to abstract the details of the problem to apply a genetic algorithm that operates with real coding. Therefore, a deterministic decoder is necessary to obtain the actual solution to the problem based on the chromosome that encodes it. 

BRKGA also requires a fitness function to evaluate each chromosome. This function takes the decoded solution as input and provides its fitness value as output. It is designed specifically for each problem.

The BRKGA optimization process is completely independent of the problem. First, a population $P$ of $p_{size}$ vectors of random-keys is initialized, this will be the initial generation. Each random-key vector has $N$ random-keys in it. The population is sorted by the fitness value $f_i$ of each chromosome to select the first $p_e$ individuals, this is, the elite of the population. The elite will be preserved in the next generation without modification. To introduce diversity, a number $p_m$ of new random-keys are also included in the next generation. The remaining chromosome of the new generation ($p_{size} - p_e - p_m$) are obtained through crossovers between elite and non-elite parents \cite{de2017comparison}.

\subsection{Adaptation of BRKGA for Constrained Clustering}

Oliviera, Chaves and Lorena (2017) proposed an adaptation of BRKGA to apply it to constrained clustering \cite{de2017comparison}.

Their method randomly initializes a population of random-key vectors, each one with $N$ random-keys. The decoder divides the interval $[0,1]$ in $K$ intervals, so there exist a correspondence between each random-key and the integer corresponding to the interval in which it is. Table \ref{tab:table1} shows an example of random-key decodification for $K = 3$. Note that extreme values 0 and 1 can also appear in a random-key vector.

\begin{table}[!h]
	\centering
	%\setlength{\arrayrulewidth}{1mm}
	\setlength{\tabcolsep}{7pt}
	\renewcommand{\arraystretch}{0.9}
	
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		Index & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ 
		\hline
		Random-key & 0.12 & 0.37 & 0.66 & 0.56 & 0.00 & 0.97 & 0.23 & 0.25 & 0.15 & 1.00 \\
		\hline
		Clusters & 1 & 2 & 2 & 2 & 1 & 3 & 1 & 3 & 1 & 3 \\ 
		\hline
		
	\end{tabular}
	\caption{Random-key decodification example \cite{de2017comparison}}
	\label{tab:table1}
\end{table}

Once the decoded solution has been obtained, the fitness value of the solution is computed as in Equation \eqref{eq1}.

\begin{equation}
f_i = z_i + \overbracket{(\mu * N * {infeasibility}_i)}^{penalty}
\label{eq1}
\end{equation}

Where $\mu$ is a high value, $infeasibility_i$ is the number of non-satisfied constraints and $z_i$ is the within-cluster-sum-of-squares which can be computed as in Equation \eqref{eq2}.

\begin{equation}
z_i = \frac{\sum_{x_a, x_b \in c_i} d_D^2(x_a,x_b)}{|c_i|} \;\;\; \forall c_i \in C
\label{eq2}
\end{equation}

Where $x_a$ and $x_b$ are instances in the cluster $c_i$ such that $a \neq b$ and the distance between each pair of instances in $c_i$ is included in the sum only once.

Oliviera, Chaves and Lorena also added a new element to BRKGA, which is a local search. This local optimization method is applied to each decoded chromosome in each generation, but its results are not transferred to the chromosome, in order to maintain the diversity. So the results of the local search are only used to update the best solution found so far if needed.

\section{The SHADE Optimization Method}

Success history based adaptive differential evolution---de ahora en adelante SHADE---is an optimization method based on differential evolution. Proposed by Tanabe and Fukunaga (2013), it was an improvement for the JADE model, created by Zhang and Sanderson \cite{tanabe2013success}\cite{zhang2009jade}.

SHADE uses a historical record of successful parameters as a mechanism for the adaptation of parameters that are involved in the process of creating new generations. Unlike JADE, which, in order to create a new generation, only considers the parameters used in the previous generation. 

\subsection{SHADE Operators}

As in differential evolution, SHADE uses muntant generation, crossover and replacement operators to explore the space of solutions and bring in new generations of individuals.

The mutation strategy used by SHADE is known as current-to-pbest/1, and the expression that generates new individuals is described in the Equation \eqref{eq3}.

\begin{equation}
m_{i,G} = p_{i,G} + F_i * (p_{pbest, G} - p_{i,G}) + F_i * (p_{r1, G} - p_{r2,G})
\label{eq3}
\end{equation}

Where $m_{i,G}$ is the mutant vector, which is generated based on an individual from the population $p_{i,G}$. The indices $r1$ and $r2$ are random values in the range $[0,N]$, different from $i$ and from each other. The individual $p_{pbest, G}$ is randomly selected from among the best $N \times p\;\;|\;\;p\in [0,1]$ individuals in the population. In this way the $p$ parameter controls the greediness of the mutation strategy. The parameter $F_i$ defines the magnitude of the operator.

After generating the mutant vector $m_{i,G}$, a crossover operator is applied to combine it with the parent $p_{i,G}$ vector, the result is the trial vector. SHADE uses the Binomial crossover operator, which is defined by the Equation \eqref{eq4}.

\begin{equation}
t_{j,i,G} = \left\{ \begin{array}{lc}
m_{j,i,G} &   if \;\; rand[0,1) \le CR_i \;\; or \;\;j = j_{rand} \\
p_{j,i,G} &  otherwise
\end{array}
\right.
\label{eq4}
\end{equation}

Where $rand[0,1)$ is a random number selected from a normal distribution in the range $[0,1)$, $j_{rand}$ is a random integer selected from the range $[1,D]$, and $CR \in [0,1]$ is the crossover ratio.

The SHADE replacement operator determines the survivors individuals for the next generation. It compares each parent $x_{i,G}$ with the trial vector $_{j,i,G}$, generated based on it. The best one of these two individuals will survive for the next generation. Equation \eqref{eq5} shows this concept.

\begin{equation}
p_{i,G + 1} = \left\{ \begin{array}{lc}
t_{i,G} &   if \;\; f(t_{i,G}) \le f(p_{i,G}) \\
p_{i,G} &  otherwise
\end{array}
\right.
\label{eq5}
\end{equation}

To maintain diversity, SHADE can make use of an external $A$ archive, in which parents $p_{i,G}$ who were replaced by their associated trial vector $t_{i,G}$ are saved. To make use of the archive, we will consider that the individual $p_{r2,G}$ from Equation \eqref{eq3} is selected from $P \cup A$, which is the union of the population and the file $A$. The file size is the same as the population size. When the size of $A$ exceeds the size $P$, a random individual is selected to remove it and make room for the new one.

The parameters $p$, $F_i$ y $CR_i$ are difficult to adjust and their selection is not trivial, as they largely determine the success of the optimization process. These are the parameters that SHADE adaptively optimizes using the mentioned history record.

\subsection{SHADE Parameter Adaptation Method}

The SHADE method saves in memory a structure with $H$ entries for parameters $F_i$ and $CR_i$, as shown in Table \ref{tab:table2}. This structure is initialized with the value $0.5$ for all entries.

\begin{table}[!h]
	\centering
	%\setlength{\arrayrulewidth}{1mm}
	\setlength{\tabcolsep}{10pt}
	\renewcommand{\arraystretch}{0.9}
	
	\begin{tabular}{|>{\centering\arraybackslash}m{1cm}  |>{\centering\arraybackslash}m{1cm}|>{\centering\arraybackslash}m{1cm}|>{\centering\arraybackslash}m{1cm}|>{\centering\arraybackslash}m{1.4cm}|>{\centering\arraybackslash}m{1.2cm}|}
		\hline
		 Index & 1 & 2 & $\cdots$ & $H - 1$ & $H$ \\ 
		 \hline
		 \hline
		 $M_{CR}$ & $M_{CR,1}$ & $M_{CR,1}$ & $\cdots$ & $M_{CR,H-1}$ & $M_{CR,H}$ \\ 
		 \hline
		 $M_{F}$ & $M_{F,1}$ & $M_{F,1}$ & $\cdots$ & $M_{F,H-1}$ & $M_{F,H}$ \\ 
		\hline
		
	\end{tabular}
	\caption{The historical memory $M_{CR}$, $M_{F}$  \cite{tanabe2013success}}
	\label{tab:table2}
\end{table}

In each generation, parameters $CR_i$ and $F_i$ are calculated on the basis of the history by applying the Equations \eqref{eq6} and \eqref{eq7}:

\begin{equation}
CR_i = randn_i(M_{CR,r_i}, 0.1)
\label{eq6}
\end{equation}

\begin{equation}
F_i = randc_i(M_{F,r_i}, 0.1)
\label{eq7}
\end{equation}

Where $randn(\mu, \sigma^2)$ and $randc(\mu, \sigma^2)$ are random values from normal and Cauchy distributions respectively, with mean $\mu$ and variance $\sigma^2$. When a value for $CR_i$ outside of the range $[0,1]$ is generated, its replaced by the allowed value. If $F_i > 1$, then it is truncated to $1$, and if $F_i < 0$, then Equation \eqref{eq7} is applied as many times as needed to obtain a legal value.

SHADE uses two auxiliar sets $S_{CR}$ and $S_F$ to store the $CR_i$ and $F_i$ values that were successfully used to generate a trial vector that replaced the parent. At the end of each generation, the content of the memory $M$ is updated following Equations \eqref{eq8} and \eqref{eq9}.

\begin{equation}
M_{CR,h,G+1} = \left\{ \begin{array}{lc}
mean_{WA} (S_{CR}) &   if \;\; S_{CR} \neq \emptyset \\
M_{CR,h,G+1} &  otherwise
\end{array}
\right.
\label{eq8}
\end{equation}

\begin{equation}
M_{F,h,G+1} = \left\{ \begin{array}{lc}
mean_{WL} (S_{F}) &   if \;\; S_{F} \neq \emptyset \\
M_{F,h,G+1} &  otherwise
\end{array}
\right.
\label{eq9}
\end{equation}

The $h \;\; (0 \le h \le H)$ index specifies the position of the memory $M$ to be updated. This index is initialized to $0$ at the beginning of the optimization process and increased by one after each generation. When $h \ge H$ then $h$ is restarted to 1. It is worth noting that, when in a generation there is no trial vector better than the parent which generated it, no update of $M$ is done.

In Equation \ref{eq8}, the term $mean_{WA} (S_{CR})$ is the wighted mean,  which is computed following Equations \eqref{eq10} and \eqref{eq11}, which were proposed by Peng et al (2009) \cite{peng2009multi} to prevent $CR$ to converge to small value.

\begin{equation}
mean_{WA} (S_{CR}) = \sum_{i = 1}^{|S_{RC}|} \omega_i * S_{RC,i}
\label{eq10}
\end{equation}

\begin{equation}
\omega_i = \frac{\Delta f_i}{\sum_{i = 1}^{|S_{RC}|} \Delta f_i}
\label{eq11}
\end{equation}

where $\Delta f_i = |f(t_i,G) - f(p_i, G)|$, which is the amount of improvement obtained from the trial vector respect to to the parent.

In Equation \ref{eq9} the term $mean_{WL} (S_{F})$ refers to the weighted Lehmer mean, which is computed as in Equation \eqref{eq12}, proposed by Tanabe and Fukunaga (2013) \cite{tanabe2013success}.

\begin{equation}
mean_{WL} (S_{F}) = \frac{\sum_{i = 1}^{|S_{F}|} \omega_i * S^2_{F,i}}{\sum_{i = 1}^{|S_{F}|} \omega_i * S_{F,i}}
\label{eq12}
\end{equation}

Unlike parameters $S_{CR}$ and $S_F$, the parameter $pbest$ from Equation \eqref{eq3}, used to set the greedyness of the mutation strategy, is not included in the optimization process. However it is not static, it is calculated for each individual of the population $p_i$ following Equation \eqref{eq13}.

\begin{equation}
pbest_i = randn[p_{min}, 0.2]
\label{eq13}
\end{equation}

where $p_{min}$ is set such that there is always al least two individuals to choose between, so $p_{min} = 2/N$.

\subsection{Adaptation of SHADE for constrained clustering}

\newpage

\section*{References}

\bibliography{mybibfile}

\end{document}